{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from spacy.en import English\n",
    "import pickle\n",
    "\n",
    "parser = English()\n",
    "# import modules & set up logging\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "\n",
    "from scipy.spatial.distance import pdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('data/Gachon Learner Corpus.xlsx', error_bad_lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Please answer the following question. Write between 100 and 150 words. 다음 질문에 100~150단어 답해주십시오.</th>\n",
       "      <th>Student number:</th>\n",
       "      <th>Class number:</th>\n",
       "      <th>Assignment #</th>\n",
       "      <th>Waiver</th>\n",
       "      <th>Gender:</th>\n",
       "      <th>Number of years you have studied English: 영어를 몇년 동안 공부하였습니까?</th>\n",
       "      <th>TOEIC Score 토익 점수</th>\n",
       "      <th>TOEFL Score 토플 점수</th>\n",
       "      <th>...</th>\n",
       "      <th>What year are you in university?</th>\n",
       "      <th>What is your native (first) language?</th>\n",
       "      <th>Father's native (first) language?</th>\n",
       "      <th>Mother's native (first) language?</th>\n",
       "      <th>What languages do you and your family speak in your home?</th>\n",
       "      <th>What language was mostly used in your Elementary School?</th>\n",
       "      <th>What language was mostly used in your Middle School?</th>\n",
       "      <th>What language was mostly used in your High School?</th>\n",
       "      <th>How confident are you in your ability to write in English?</th>\n",
       "      <th>Why are you studying English?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-03-07 20:13:28</td>\n",
       "      <td>In Korea when people small talk to each other ...</td>\n",
       "      <td>21011008</td>\n",
       "      <td>10075009 월/목 오후1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male (Man) 남</td>\n",
       "      <td>12</td>\n",
       "      <td>780</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>Junior (3학년)</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "      <td>Fulfilling Academic Requirements 졸업조건을 충족시키기 위해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-17 05:32:16</td>\n",
       "      <td>I have ever been to austraila in a month. In t...</td>\n",
       "      <td>21011008</td>\n",
       "      <td>10075009 월/목 오후1:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Male (Man) 남</td>\n",
       "      <td>12</td>\n",
       "      <td>780</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>Junior (3학년)</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "      <td>Fulfilling Academic Requirements 졸업조건을 충족시키기 위해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-03-26 21:48:43</td>\n",
       "      <td>The 'sin sae gye' is the best movie i've ever ...</td>\n",
       "      <td>21011008</td>\n",
       "      <td>10075009 월/목 오후1:00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Male (Man) 남</td>\n",
       "      <td>12</td>\n",
       "      <td>780</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>Junior (3학년)</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "      <td>Fulfilling Academic Requirements 졸업조건을 충족시키기 위해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-04-03 04:42:47</td>\n",
       "      <td>I think if children are allowed to watch viole...</td>\n",
       "      <td>21011008</td>\n",
       "      <td>10075009 월/목 오후1:00</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Male (Man) 남</td>\n",
       "      <td>12</td>\n",
       "      <td>780</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>Junior (3학년)</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "      <td>Fulfilling Academic Requirements 졸업조건을 충족시키기 위해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-04-11 22:49:48</td>\n",
       "      <td>If i am the manager of a hotel, i will have wa...</td>\n",
       "      <td>21011008</td>\n",
       "      <td>10075009 월/목 오후1:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Male (Man) 남</td>\n",
       "      <td>12</td>\n",
       "      <td>780</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>Junior (3학년)</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>Korean</td>\n",
       "      <td>3</td>\n",
       "      <td>Fulfilling Academic Requirements 졸업조건을 충족시키기 위해</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Timestamp  \\\n",
       "0  2014-03-07 20:13:28   \n",
       "1  2014-03-17 05:32:16   \n",
       "2  2014-03-26 21:48:43   \n",
       "3  2014-04-03 04:42:47   \n",
       "4  2014-04-11 22:49:48   \n",
       "\n",
       "  Please answer the following question. Write between 100 and 150 words. 다음 질문에 100~150단어 답해주십시오.  \\\n",
       "0  In Korea when people small talk to each other ...                                                \n",
       "1  I have ever been to austraila in a month. In t...                                                \n",
       "2  The 'sin sae gye' is the best movie i've ever ...                                                \n",
       "3  I think if children are allowed to watch viole...                                                \n",
       "4  If i am the manager of a hotel, i will have wa...                                                \n",
       "\n",
       "   Student number:        Class number:  Assignment #  Waiver       Gender:  \\\n",
       "0         21011008  10075009 월/목 오후1:00             1       1  Male (Man) 남   \n",
       "1         21011008  10075009 월/목 오후1:00             2       1  Male (Man) 남   \n",
       "2         21011008  10075009 월/목 오후1:00             3       1  Male (Man) 남   \n",
       "3         21011008  10075009 월/목 오후1:00             4       1  Male (Man) 남   \n",
       "4         21011008  10075009 월/목 오후1:00             5       1  Male (Man) 남   \n",
       "\n",
       "  Number of years you have studied English: 영어를 몇년 동안 공부하였습니까?  \\\n",
       "0                                                 12             \n",
       "1                                                 12             \n",
       "2                                                 12             \n",
       "3                                                 12             \n",
       "4                                                 12             \n",
       "\n",
       "  TOEIC Score 토익 점수 TOEFL Score 토플 점수  \\\n",
       "0               780                 x   \n",
       "1               780                 x   \n",
       "2               780                 x   \n",
       "3               780                 x   \n",
       "4               780                 x   \n",
       "\n",
       "                        ...                         \\\n",
       "0                       ...                          \n",
       "1                       ...                          \n",
       "2                       ...                          \n",
       "3                       ...                          \n",
       "4                       ...                          \n",
       "\n",
       "  What year are you in university? What is your native (first) language?  \\\n",
       "0                     Junior (3학년)                                Korean   \n",
       "1                     Junior (3학년)                                Korean   \n",
       "2                     Junior (3학년)                                Korean   \n",
       "3                     Junior (3학년)                                Korean   \n",
       "4                     Junior (3학년)                                Korean   \n",
       "\n",
       "  Father's native (first) language? Mother's native (first) language?  \\\n",
       "0                            Korean                            Korean   \n",
       "1                            Korean                            Korean   \n",
       "2                            Korean                            Korean   \n",
       "3                            Korean                            Korean   \n",
       "4                            Korean                            Korean   \n",
       "\n",
       "  What languages do you and your family speak in your home?  \\\n",
       "0                                             Korean          \n",
       "1                                             Korean          \n",
       "2                                             Korean          \n",
       "3                                             Korean          \n",
       "4                                             Korean          \n",
       "\n",
       "  What language was mostly used in your Elementary School?  \\\n",
       "0                                             Korean         \n",
       "1                                             Korean         \n",
       "2                                             Korean         \n",
       "3                                             Korean         \n",
       "4                                             Korean         \n",
       "\n",
       "  What language was mostly used in your Middle School?  \\\n",
       "0                                             Korean     \n",
       "1                                             Korean     \n",
       "2                                             Korean     \n",
       "3                                             Korean     \n",
       "4                                             Korean     \n",
       "\n",
       "  What language was mostly used in your High School?  \\\n",
       "0                                             Korean   \n",
       "1                                             Korean   \n",
       "2                                             Korean   \n",
       "3                                             Korean   \n",
       "4                                             Korean   \n",
       "\n",
       "  How confident are you in your ability to write in English?  \\\n",
       "0                                                  3           \n",
       "1                                                  3           \n",
       "2                                                  3           \n",
       "3                                                  3           \n",
       "4                                                  3           \n",
       "\n",
       "                     Why are you studying English?  \n",
       "0  Fulfilling Academic Requirements 졸업조건을 충족시키기 위해  \n",
       "1  Fulfilling Academic Requirements 졸업조건을 충족시키기 위해  \n",
       "2  Fulfilling Academic Requirements 졸업조건을 충족시키기 위해  \n",
       "3  Fulfilling Academic Requirements 졸업조건을 충족시키기 위해  \n",
       "4  Fulfilling Academic Requirements 졸업조건을 충족시키기 위해  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df.ix[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        In Korea when people small talk to each other ...\n",
       "1        I have ever been to austraila in a month. In t...\n",
       "2        The 'sin sae gye' is the best movie i've ever ...\n",
       "3        I think if children are allowed to watch viole...\n",
       "4        If i am the manager of a hotel, i will have wa...\n",
       "5        When i choose the hotel i will check on the mi...\n",
       "6        Changing driving line without turnig on a dire...\n",
       "7        Recently most drivers in my city are good beca...\n",
       "8        I have used BB cream  effecting my skin white ...\n",
       "9        My weapon improving my appearance is a hair st...\n",
       "10       In Korea, lt's not polite to ask about someone...\n",
       "11       I Like the thrill. Expecially I like to go an ...\n",
       "12       I like to watch movies at home. movie tickets ...\n",
       "13       In my opinion children shouldn't watch violent...\n",
       "14       I think Wake-up service is important. Because ...\n",
       "15       Hotel's charges are important to me. Because I...\n",
       "16       I like to drive a car. But some drivers make m...\n",
       "17       I think most drivers in my city are bad driver...\n",
       "18       Everyday I use a razor in the morning. My bear...\n",
       "19       I think that appearance is important. So many ...\n",
       "20       1. Talking too personal things.\\n - It is bett...\n",
       "21       1. Going to abroad\\nI have been to America whe...\n",
       "22       Fever Pitch(2005)\\n This film is about a love ...\n",
       "23       We should not let childeren to watch violence ...\n",
       "24       Except hotel services in the rop notch2, I wil...\n",
       "25       To me, free wifi service is the most important...\n",
       "26       'The bullet taxi' is the most hateful and agre...\n",
       "27       Half and half I think. I usually taked taxi in...\n",
       "28       1.Sunscreen\\nI always put sunscreen on my face...\n",
       "29       1.Steady exercise\\n Stedy exercise makes me be...\n",
       "                               ...                        \n",
       "25043    If I were the manager of the hotel, I would ru...\n",
       "25044    When i choose a hotel, I consider sightseeing ...\n",
       "25045    I think that the most aggressive driving behav...\n",
       "25046    I think that our city drivers is bad drivers. ...\n",
       "25047    I use a toothbrush everyday. I brush tooth the...\n",
       "25048    The best way to improve their appearance is to...\n",
       "25049    I think we should avoid talking about income, ...\n",
       "25050    I went to Caribbean Bay last summer break. I e...\n",
       "25051    Usually, people thinks children follow violent...\n",
       "25052    I think children cannot be allowed to watch vi...\n",
       "25053    I think location, cleanliness, bathtub it the ...\n",
       "25054    I think most drivers in my city are bad driver...\n",
       "25055    I don’t use personal care and beauty products....\n",
       "25056    I think use personal care products, make up, a...\n",
       "25057    People should avoid Sexual minority. Because I...\n",
       "25058    I am thrilled when watching a scared movie. In...\n",
       "25059    My best movie is World War Z. It's Zombie movi...\n",
       "25060    Children shouldn't be allowed to watch violent...\n",
       "25061    If I am the manager of a hotel, I will wake-up...\n",
       "25062    I sometimes use personal care. For example I h...\n",
       "25063    I think that make-up is the best way for someo...\n",
       "25064    Age is one of the topics to avoid during small...\n",
       "25065    At least in Korea, I don’t think so. In Korea,...\n",
       "25066    I think, people have a difference of awareness...\n",
       "25067    I think a children’s development can be entire...\n",
       "25068    I love many kinds of art such like music, movi...\n",
       "25069    I think people are born with a preference or a...\n",
       "25070    When I am 7 years old, I had my first computer...\n",
       "25071    Yes. Nowadays almost everyone has a smart phon...\n",
       "25072    If a cashier gave me too much change, I will g...\n",
       "Name: Please answer the following question. Write between 100 and 150 words. 다음 질문에 100~150단어 답해주십시오., dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25068    I love many kinds of art such like music, movi...\n",
       "25069    I think people are born with a preference or a...\n",
       "25070    When I am 7 years old, I had my first computer...\n",
       "25071    Yes. Nowadays almost everyone has a smart phon...\n",
       "25072    If a cashier gave me too much change, I will g...\n",
       "Name: Please answer the following question. Write between 100 and 150 words. 다음 질문에 100~150단어 답해주십시오., dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_list=df1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25073\n"
     ]
    }
   ],
   "source": [
    "print (len(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "sent_list=[]\n",
    "for item in text_list:\n",
    "    try:\n",
    "        sent_tokenize_list = sent_tokenize(item)\n",
    "        sent_list.append(sent_tokenize_list)   \n",
    "    except:\n",
    "        print (item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25072\n"
     ]
    }
   ],
   "source": [
    "print (len(sent_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a cashier gave me too much change, I will give it back to cashier.\n",
      "People can make mistakes.\n",
      "And person who knows mistakes of others have to correct.\n",
      "This is the result of learning.\n",
      "Because money is not that important to me, I can put this idea into action easily.\n",
      "There is a lot of case similar to this.\n",
      "But the object, money in this case, can be changed.\n",
      "It can be a life or love or authority or honor and so on.\n",
      "Moreover, there is difference between thinking and action.\n",
      "If a situation changes, I can change my thinking or action too.\n",
      "There is no only one answer.\n"
     ]
    }
   ],
   "source": [
    "for item in sent_tokenize_list:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1=df1[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'sent': sent_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25067</th>\n",
       "      <td>[I love many kinds of art such like music, mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25068</th>\n",
       "      <td>[I think people are born with a preference or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25069</th>\n",
       "      <td>[When I am 7 years old, I had my first compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25070</th>\n",
       "      <td>[Yes., Nowadays almost everyone has a smart ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25071</th>\n",
       "      <td>[If a cashier gave me too much change, I will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sent\n",
       "25067  [I love many kinds of art such like music, mov...\n",
       "25068  [I think people are born with a preference or ...\n",
       "25069  [When I am 7 years old, I had my first compute...\n",
       "25070  [Yes., Nowadays almost everyone has a smart ph...\n",
       "25071  [If a cashier gave me too much change, I will ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"In Korea when people small talk to each other they have to avoid talking about other's salary.\",\n",
       " 'because they think he or she wants to classify me as salary.',\n",
       " 'That must be rude people think.',\n",
       " 'Also people do not quest weight especially in case they are girls.',\n",
       " 'korea women want to hide her secret and man have responsibillity to hide her secret.',\n",
       " \"That's the korea manner even though another country's manner is.\",\n",
       " 'Finally professional questions have to be avoided when small talking to each other.',\n",
       " \"because that's required specaility knowledge, so that each talker have burden can not lead the communication.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_list=[]\n",
    "for item in sent_list:\n",
    "    for sent in item:\n",
    "        word_list.append(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['In',\n",
       "  'Korea',\n",
       "  'when',\n",
       "  'people',\n",
       "  'small',\n",
       "  'talk',\n",
       "  'to',\n",
       "  'each',\n",
       "  'other',\n",
       "  'they',\n",
       "  'have',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'talking',\n",
       "  'about',\n",
       "  'other',\n",
       "  \"'s\",\n",
       "  'salary',\n",
       "  '.'],\n",
       " ['because',\n",
       "  'they',\n",
       "  'think',\n",
       "  'he',\n",
       "  'or',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'classify',\n",
       "  'me',\n",
       "  'as',\n",
       "  'salary',\n",
       "  '.']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in word_list:\n",
    "    for word in item:\n",
    "        if word.isalnum()==False:\n",
    "            item.remove(word)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in word_list:\n",
    "    for word in item:\n",
    "        word=word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238644\n"
     ]
    }
   ],
   "source": [
    "print (len(word_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower_word_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in word_list:\n",
    "    d_sent=[]\n",
    "    for word in item:\n",
    "        d_sent.append(word.lower())\n",
    "    lower_word_list.append(d_sent)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in',\n",
       " 'korea',\n",
       " 'when',\n",
       " 'people',\n",
       " 'small',\n",
       " 'talk',\n",
       " 'to',\n",
       " 'each',\n",
       " 'other',\n",
       " 'they',\n",
       " 'have',\n",
       " 'to',\n",
       " 'avoid',\n",
       " 'talking',\n",
       " 'about',\n",
       " 'other',\n",
       " 'salary']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_word_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-26 10:10:01,003 : INFO : collecting all words and their counts\n",
      "2017-01-26 10:10:01,004 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-26 10:10:01,061 : INFO : PROGRESS: at sentence #10000, processed 108735 words, keeping 6925 word types\n",
      "2017-01-26 10:10:01,104 : INFO : PROGRESS: at sentence #20000, processed 212731 words, keeping 9823 word types\n",
      "2017-01-26 10:10:01,150 : INFO : PROGRESS: at sentence #30000, processed 312808 words, keeping 11798 word types\n",
      "2017-01-26 10:10:01,193 : INFO : PROGRESS: at sentence #40000, processed 415371 words, keeping 13557 word types\n",
      "2017-01-26 10:10:01,240 : INFO : PROGRESS: at sentence #50000, processed 522416 words, keeping 15211 word types\n",
      "2017-01-26 10:10:01,294 : INFO : PROGRESS: at sentence #60000, processed 632351 words, keeping 16800 word types\n",
      "2017-01-26 10:10:01,336 : INFO : PROGRESS: at sentence #70000, processed 736853 words, keeping 17929 word types\n",
      "2017-01-26 10:10:01,380 : INFO : PROGRESS: at sentence #80000, processed 838952 words, keeping 19080 word types\n",
      "2017-01-26 10:10:01,419 : INFO : PROGRESS: at sentence #90000, processed 938969 words, keeping 20144 word types\n",
      "2017-01-26 10:10:01,462 : INFO : PROGRESS: at sentence #100000, processed 1043167 words, keeping 21346 word types\n",
      "2017-01-26 10:10:01,503 : INFO : PROGRESS: at sentence #110000, processed 1142460 words, keeping 22273 word types\n",
      "2017-01-26 10:10:01,547 : INFO : PROGRESS: at sentence #120000, processed 1247951 words, keeping 23193 word types\n",
      "2017-01-26 10:10:01,587 : INFO : PROGRESS: at sentence #130000, processed 1354130 words, keeping 24302 word types\n",
      "2017-01-26 10:10:01,635 : INFO : PROGRESS: at sentence #140000, processed 1458374 words, keeping 25234 word types\n",
      "2017-01-26 10:10:01,684 : INFO : PROGRESS: at sentence #150000, processed 1570634 words, keeping 26276 word types\n",
      "2017-01-26 10:10:01,731 : INFO : PROGRESS: at sentence #160000, processed 1671898 words, keeping 27050 word types\n",
      "2017-01-26 10:10:01,795 : INFO : PROGRESS: at sentence #170000, processed 1777483 words, keeping 27871 word types\n",
      "2017-01-26 10:10:01,840 : INFO : PROGRESS: at sentence #180000, processed 1878731 words, keeping 28698 word types\n",
      "2017-01-26 10:10:01,884 : INFO : PROGRESS: at sentence #190000, processed 1983894 words, keeping 29458 word types\n",
      "2017-01-26 10:10:01,937 : INFO : PROGRESS: at sentence #200000, processed 2083547 words, keeping 30102 word types\n",
      "2017-01-26 10:10:02,003 : INFO : PROGRESS: at sentence #210000, processed 2198517 words, keeping 30941 word types\n",
      "2017-01-26 10:10:02,053 : INFO : PROGRESS: at sentence #220000, processed 2306151 words, keeping 31551 word types\n",
      "2017-01-26 10:10:02,106 : INFO : PROGRESS: at sentence #230000, processed 2417206 words, keeping 32176 word types\n",
      "2017-01-26 10:10:02,147 : INFO : collected 32711 word types from a corpus of 2516354 raw words and 238644 sentences\n",
      "2017-01-26 10:10:02,148 : INFO : Loading a fresh vocabulary\n",
      "2017-01-26 10:10:02,232 : INFO : min_count=2 retains 17739 unique words (54% of original 32711, drops 14972)\n",
      "2017-01-26 10:10:02,233 : INFO : min_count=2 leaves 2501382 word corpus (99% of original 2516354, drops 14972)\n",
      "2017-01-26 10:10:02,318 : INFO : deleting the raw counts dictionary of 32711 items\n",
      "2017-01-26 10:10:02,320 : INFO : sample=0.001 downsamples 60 most-common words\n",
      "2017-01-26 10:10:02,321 : INFO : downsampling leaves estimated 1822362 word corpus (72.9% of prior 2501382)\n",
      "2017-01-26 10:10:02,322 : INFO : estimated required memory for 17739 words and 100 dimensions: 23060700 bytes\n",
      "2017-01-26 10:10:02,407 : INFO : resetting layer weights\n",
      "2017-01-26 10:10:02,842 : INFO : training model with 3 workers on 17739 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-01-26 10:10:02,843 : INFO : expecting 238644 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-26 10:10:03,853 : INFO : PROGRESS: at 6.55% examples, 592904 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:04,860 : INFO : PROGRESS: at 13.63% examples, 612689 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:05,869 : INFO : PROGRESS: at 20.42% examples, 616680 words/s, in_qsize 6, out_qsize 0\n",
      "2017-01-26 10:10:06,870 : INFO : PROGRESS: at 27.56% examples, 623371 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-26 10:10:07,878 : INFO : PROGRESS: at 35.01% examples, 632107 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-26 10:10:08,889 : INFO : PROGRESS: at 42.34% examples, 639093 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:09,898 : INFO : PROGRESS: at 50.02% examples, 645106 words/s, in_qsize 6, out_qsize 0\n",
      "2017-01-26 10:10:10,903 : INFO : PROGRESS: at 57.55% examples, 649924 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:11,910 : INFO : PROGRESS: at 64.81% examples, 652032 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:12,915 : INFO : PROGRESS: at 72.21% examples, 653111 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:13,921 : INFO : PROGRESS: at 79.25% examples, 651902 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:14,927 : INFO : PROGRESS: at 86.54% examples, 652761 words/s, in_qsize 6, out_qsize 0\n",
      "2017-01-26 10:10:15,940 : INFO : PROGRESS: at 94.00% examples, 653637 words/s, in_qsize 5, out_qsize 0\n",
      "2017-01-26 10:10:16,737 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-26 10:10:16,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-26 10:10:16,760 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-26 10:10:16,760 : INFO : training on 12581770 raw words (9112107 effective words) took 13.9s, 655170 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(lower_word_list, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-26 10:13:47,111 : INFO : saving Word2Vec object under wordvec/uvecmodel, separately None\n",
      "2017-01-26 10:13:47,113 : INFO : not storing attribute cum_table\n",
      "2017-01-26 10:13:47,114 : INFO : not storing attribute syn0norm\n",
      "2017-01-26 10:13:47,329 : INFO : saved wordvec/uvecmodel\n"
     ]
    }
   ],
   "source": [
    "model.save('wordvec/uvecmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_models(word):\n",
    "    model.most_similar(['funny'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-26 10:14:46,776 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('trend', 0.5873164534568787)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['women', 'king'], negative=['man'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exciting', 0.8497126698493958),\n",
       " ('sad', 0.8396835327148438),\n",
       " ('fantastic', 0.8293112516403198),\n",
       " ('touching', 0.818619430065155),\n",
       " ('awesome', 0.810546338558197),\n",
       " ('fascinating', 0.8035693168640137),\n",
       " ('fun', 0.7975648045539856),\n",
       " ('amazing', 0.7905359268188477),\n",
       " ('shocking', 0.7864383459091187),\n",
       " ('realistic', 0.7632798552513123)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['funny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('wordvec/univ_kor.pkl', 'wb') as f:\n",
    "    pickle.dump(lower_word_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:insight]",
   "language": "python",
   "name": "conda-env-insight-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
