{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files=os.listdir('Lang_Kor/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "from guess_language import guess_language\n",
    "import re\n",
    "import pickle\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_datafile(files):\n",
    "    raw_text=open('Lang_Kor/'+files,'r')\n",
    "    \n",
    "    #Remove UTF-8 Char\n",
    "    messy_list=[]\n",
    "    for item in raw_text:\n",
    "        messy_list.append(re.sub(r'(\\\\+([A-z]|[0-9]){3})','',item))\n",
    "    \n",
    "    #Prep the sentences for tokenization\n",
    "    Eng_sent_prep=[]\n",
    "    for item in messy_list:\n",
    "        Eng_sent_prep.append((re.sub(r'(.!?)([A-Z]+)', r'\\1 \\2', item)))\n",
    "    \n",
    "    #Sentence tokenization\n",
    "    Eng_sent=[]\n",
    "    for line in Eng_sent_prep:\n",
    "        sent_tokenize_list = sent_tokenize(line)\n",
    "        Eng_sent.append(sent_tokenize_list)\n",
    "    flatten_sent = [val for sublist in Eng_sent for val in sublist]\n",
    "    \n",
    "    #Remove non-english sentences\n",
    "    Eng_only=[]\n",
    "    for sent in flatten_sent:\n",
    "        if guess_language(sent) =='en':\n",
    "            Eng_only.append(sent)\n",
    "            \n",
    "    #Create word tokenized list\n",
    "    Eng_word_ml=[]\n",
    "    for item in Eng_only:\n",
    "        dsent=[]\n",
    "        words= word_tokenize(item)\n",
    "        for item in words:\n",
    "            if item.isalnum() == False:\n",
    "                pass\n",
    "            else:\n",
    "                dsent.append(item.lower())\n",
    "        if len(dsent)>1:\n",
    "            Eng_word_ml.append(dsent)\n",
    "            \n",
    "    #Remove random char\n",
    "    Eng_word_ml_cleaned=[]\n",
    "    for sent in Eng_word_ml:\n",
    "        dsent=[]\n",
    "        if len(sent)>2:\n",
    "            for word in sent:\n",
    "                if word in 'bcdfghjklmnopqrstvwxz':\n",
    "                    pass\n",
    "                else:\n",
    "                    dsent.append(word)\n",
    "            Eng_word_ml_cleaned.append(dsent)    \n",
    "            \n",
    "    return Eng_word_ml_cleaned        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_words=[]\n",
    "for file in files:\n",
    "    words=[]\n",
    "    words=clean_datafile(file)\n",
    "    total_words.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatten_words = [val for sublist in total_words for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82710"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pd_frame_maker(sentlist, label):\n",
    "    df=pd.DataFrame({'sent': sentlist, 'label': label})\n",
    "    df['sentence']=df['sent'].apply(lambda x: \" \".join(x))\n",
    "    df['length']=df['sent'].apply(lambda x: len(x))\n",
    "    df=df[df['length']>1]\n",
    "    df['sentence']=df['sentence'].drop_duplicates()\n",
    "    df['language']=df['sentence'].apply(lambda x: guess_language(str(x)))\n",
    "    df=df[df['language']=='en']\n",
    "    df = df.dropna()   \n",
    "    df = df.ix[:,:4]\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd_frame_maker(flatten_words,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sent</th>\n",
       "      <th>sentence</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77233</th>\n",
       "      <td>1</td>\n",
       "      <td>[i, am, so, regretful, to, have, done, i, real...</td>\n",
       "      <td>i am so regretful to have done i really want t...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77234</th>\n",
       "      <td>1</td>\n",
       "      <td>[today, temperature, dropped, to, 12, degrees,...</td>\n",
       "      <td>today temperature dropped to 12 degrees below ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77235</th>\n",
       "      <td>1</td>\n",
       "      <td>[i, think, today, was, the, lowest, temperatur...</td>\n",
       "      <td>i think today was the lowest temperature in th...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77236</th>\n",
       "      <td>1</td>\n",
       "      <td>[and, also, it, makes, the, poor, feel, really...</td>\n",
       "      <td>and also it makes the poor feel really bad</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77237</th>\n",
       "      <td>1</td>\n",
       "      <td>[i, am, expecting, a, normal]</td>\n",
       "      <td>i am expecting a normal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               sent  \\\n",
       "77233      1  [i, am, so, regretful, to, have, done, i, real...   \n",
       "77234      1  [today, temperature, dropped, to, 12, degrees,...   \n",
       "77235      1  [i, think, today, was, the, lowest, temperatur...   \n",
       "77236      1  [and, also, it, makes, the, poor, feel, really...   \n",
       "77237      1                      [i, am, expecting, a, normal]   \n",
       "\n",
       "                                                sentence  length  \n",
       "77233  i am so regretful to have done i really want t...      17  \n",
       "77234  today temperature dropped to 12 degrees below ...      17  \n",
       "77235  i think today was the lowest temperature in th...      10  \n",
       "77236         and also it makes the poor feel really bad       9  \n",
       "77237                            i am expecting a normal       5  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66259"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('data/lang8_kor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:insight]",
   "language": "python",
   "name": "conda-env-insight-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
